{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb3ae7f5",
   "metadata": {},
   "source": [
    "# Vector databases\n",
    "\n",
    "Creating and configuring a Vector Database to Store Document Embeddings\n",
    "  \n",
    "Later we will do Similarity searches  \n",
    "\n",
    "\n",
    "### Vector databases vs traditional databases like SQL\n",
    "Vector databases can index and search quickly for similar vectors using similarity algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dd9af56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "import urllib\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1b7bffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of chunks:  215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jayne\\AppData\\Local\\Continuum\\anaconda3\\envs\\genai\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# load and prepare some text\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/BYlUHaillwM8EUItaIytHQ/companypolicies.txt\"\n",
    "\n",
    "filename = 'data/companypolicies.txt'\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "loader = TextLoader(\"data/companypolicies.txt\")\n",
    "data = loader.load()\n",
    "\n",
    "# split the data\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(data)\n",
    "print(\"Length of chunks: \", len(chunks))\n",
    "\n",
    "# embedding model\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "huggingface_embedding = HuggingFaceEmbeddings(model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad50a29",
   "metadata": {},
   "source": [
    "## Vector store\n",
    "\n",
    "### ChromaDB\n",
    "We need to start by creating an ID list that will be used to assign each chunk a unique identifier, allowing you to track them later in the vector database. The length of this list should match the length of the chunks.  \n",
    "  \n",
    "The IDs should be in string format.\n",
    "  \n",
    "\n",
    "We then use the embedding model to create embeddings for each chunk and then store them in the Chroma database.  \n",
    "  \n",
    "We can then use the method .collection.get() to print some of the chunks indexed by their IDs.  \n",
    "Although the chunks are stored in the database in embedding format, when you retrieve and print them by their IDs, the database will return the chunk text information instead of the embedding vectors.\n",
    "\n",
    "   \n",
    "\n",
    "FIASS is another vector database that is supported by LangChain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f67bba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create id list\n",
    "ids = [str(i) for i in range(0, len(chunks))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc586b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x253cd05d7f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create embeddings for each chunk and then store them in the Chroma database.  \n",
    "# dont need a separate embedding step like we did before \n",
    "vectordb = Chroma.from_documents(chunks, huggingface_embedding, ids=ids)\n",
    "vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87ecf007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': ['0'], 'embeddings': None, 'documents': ['1.\\tCode of Conduct'], 'uris': None, 'included': ['metadatas', 'documents'], 'data': None, 'metadatas': [{'source': 'data/companypolicies.txt'}]}\n",
      "{'ids': ['1'], 'embeddings': None, 'documents': ['Our Code of Conduct outlines the fundamental principles and ethical standards that guide every'], 'uris': None, 'included': ['metadatas', 'documents'], 'data': None, 'metadatas': [{'source': 'data/companypolicies.txt'}]}\n",
      "{'ids': ['2'], 'embeddings': None, 'documents': ['that guide every member of our organization. We are committed to maintaining a workplace that is'], 'uris': None, 'included': ['metadatas', 'documents'], 'data': None, 'metadatas': [{'source': 'data/companypolicies.txt'}]}\n"
     ]
    }
   ],
   "source": [
    "# print some of the chunks indexed by their IDs\n",
    "for i in range(3):\n",
    "    print(vectordb._collection.get(ids=str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dda5f9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': ['1', '2', '6'], 'embeddings': None, 'documents': ['Our Code of Conduct outlines the fundamental principles and ethical standards that guide every', 'that guide every member of our organization. We are committed to maintaining a workplace that is', 'clients, or the broader community. We respect and protect sensitive information, and we avoid'], 'uris': None, 'included': ['metadatas', 'documents'], 'data': None, 'metadatas': [{'source': 'data/companypolicies.txt'}, {'source': 'data/companypolicies.txt'}, {'source': 'data/companypolicies.txt'}]}\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.get(ids=[\"1\",\"2\",\"6\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ebdb1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see the length of the vector database, which should be the same as the length of chunks.\n",
    "vectordb._collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93da209",
   "metadata": {},
   "source": [
    "# Similarity search\n",
    "Similarity search in a vector database involves finding items that are most similar to a given query item based on their vector representations.  \n",
    "\n",
    "The search algorithm identifies and retrieves the vectors of the data objects with the closest vector distances to the query, enabling efficient and accurate identification of similar items in large datasets.\n",
    "\n",
    "LangChain supports similarity search in vector stores using the method .similarity_search().\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50745d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/companypolicies.txt'}, page_content='3.\\tInternet and Email Policy'),\n",
       " Document(metadata={'source': 'data/companypolicies.txt'}, page_content='Our Internet and Email Policy aims to promote safe, responsible usage of digital communication')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample query\n",
    "query = \"Email policy\"\n",
    "\n",
    "# by default, the top four closest vectors to the query are returned\n",
    "docs = vectordb.similarity_search(query, k=2)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b1249e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/companypolicies.txt'}, page_content='3.\\tInternet and Email Policy')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can specify the top k results to return\n",
    "vectordb.similarity_search(query, k = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32640d3",
   "metadata": {},
   "source": [
    "# Managing vector store: Adding, updating, and deleting entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10702f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to add a document\n",
    "\n",
    "# sample text \n",
    "text = \"This is a study notebook about building a LLM.\"\n",
    "\n",
    "new_chunk =  Document(\n",
    "    page_content=text,\n",
    "    metadata={\n",
    "        \"source\": \"emma.com\",\n",
    "        \"page\": 1\n",
    "    }\n",
    ")\n",
    "\n",
    "# has to be a list\n",
    "new_chunks = [new_chunk]\n",
    "\n",
    "# add the new document to the end of our db\n",
    "vectordb.add_documents(\n",
    "    new_chunks,\n",
    "    ids=[\"215\"]\n",
    ")\n",
    "\n",
    "vectordb._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0313243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': ['215'], 'embeddings': None, 'documents': ['This is a study notebook about building a LLM.'], 'uris': None, 'included': ['metadatas', 'documents'], 'data': None, 'metadatas': [{'page': 1, 'source': 'ibm.com'}]}\n"
     ]
    }
   ],
   "source": [
    "# the new document added to our db\n",
    "print(vectordb._collection.get(ids=['215']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9430a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': ['215'], 'embeddings': None, 'documents': ['I am updating this document'], 'uris': None, 'included': ['metadatas', 'documents'], 'data': None, 'metadatas': [{'source': 'emmajayne.com', 'page': 1}]}\n"
     ]
    }
   ],
   "source": [
    "# to update a document \n",
    "\n",
    "update_chunk =  Document(\n",
    "    page_content=\"I am updating this document\",\n",
    "    metadata={\n",
    "        \"source\": \"emmajayne.com\",\n",
    "        \"page\": 1\n",
    "    }\n",
    ")\n",
    "\n",
    "vectordb.update_document(\n",
    "    '215',\n",
    "    update_chunk,\n",
    ")\n",
    "\n",
    "print(vectordb._collection.get(ids=['215']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b0939ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [], 'embeddings': None, 'documents': [], 'uris': None, 'included': ['metadatas', 'documents'], 'data': None, 'metadatas': []}\n"
     ]
    }
   ],
   "source": [
    "# to delete a document from the vector database\n",
    "vectordb._collection.delete(ids=['215'])\n",
    "print(vectordb._collection.get(ids=['215']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
