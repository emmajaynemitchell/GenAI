{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7a85e4c",
   "metadata": {},
   "source": [
    "# Document embeddings\n",
    "\n",
    "In the context of NLP, document embedding refers to the process of converting textual documents into numerical vectors. These vectors capture the semantic meaning of the documents, enabling machines to understand and process human language.  \n",
    "  \n",
    "  \n",
    "### **Steps to embed documents:**  \n",
    "1) Preparation of data:\n",
    "    Clean and preprocess the data, eg., removing special characters, normalizing text and tokenization.\n",
    "    Organize your documents into a format that is compatible with model's input requirements, typically as a list of strings or a data set.  You cannot imput an entire large document as is because embedding models have maximum input token limits, you must split the documents into chunks first.  \n",
    "\n",
    "2) Load the pretrained embedding model, which is optimized for generating document embeddings.\n",
    "\n",
    "3) Embedding process:\n",
    "\n",
    "    Pass the prepared documents through the embedding model.\n",
    "    The model will convert each document into a fixed-size numerical vector. These vectors are dense and capture the semantic meaning of the documents.\n",
    "\n",
    "4) Postprocessing:\n",
    "\n",
    "    After obtaining the embeddings, consider normalizing the vectors if necessary.\n",
    "    Store the embeddings in a suitable format, such as a database, for further use in downstream tasks.\n",
    "\n",
    "\n",
    "\n",
    "### Applications of document embeddings\n",
    "- Document clustering:  \n",
    "Use the embeddings to group similar documents together. This is particularly useful in organizing large document collections or creating topic-based clusters.\n",
    "\n",
    "- Semantic search:  \n",
    "Implement a semantic search engine where queries are matched with documents based on their semantic similarity rather than just keyword matching.\n",
    "\n",
    "- Text classification:  \n",
    "Utilize the embeddings as input features for classification models to categorize documents into predefined labels.\n",
    "\n",
    "\n",
    "## Which embedding model to use?\n",
    "Good question. Here's a leaderboard that might help  \n",
    "https://huggingface.co/spaces/mteb/leaderboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ead212e",
   "metadata": {},
   "source": [
    "## Hugging Face embedding model\n",
    "\n",
    "We will use the all-mpnet-base-v2 embedding model.  \n",
    "It is a sentence-transformers model. It maps sentences and paragraphs to a 768-dimensional dense vector space and can be used for tasks like clustering or semantic search. It used the pre-trained Microsoft/money-base model and fine-tuned it on a 1B sentence pairs dataset.  \n",
    "https://huggingface.co/sentence-transformers/all-mpnet-base-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02153e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import urllib.request\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "152f49b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "# lets get some data and split it into chunks\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/Ec5f3KYU1CpbKRp1whFLZw/new-Policies.txt\"\n",
    "filename = 'data/new-Policies.txt'\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "loader = TextLoader(\"data/new-Policies.txt\")\n",
    "data = loader.load()\n",
    "\n",
    "# split the text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_text(data[0].page_content)\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7f0811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jayne\\AppData\\Local\\Continuum\\anaconda3\\envs\\genai\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\jayne\\AppData\\Local\\Continuum\\anaconda3\\envs\\genai\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\jayne\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "# defining the embedding model\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "huggingface_embedding = HuggingFaceEmbeddings(model_name=model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66dc67c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0271061509847641,\n",
       " 0.011331789195537567,\n",
       " -0.0019524155650287867,\n",
       " -0.03695131093263626,\n",
       " 0.01776493526995182]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets create a query and embed it\n",
    "\n",
    "query = \"How are you?\"\n",
    "query_result = huggingface_embedding.embed_query(query)\n",
    "query_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cd9b6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a8155ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05780600383877754,\n",
       " 0.04059649258852005,\n",
       " 0.013996032066643238,\n",
       " 0.009279176592826843,\n",
       " -0.03389701619744301]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now lets embed the document\n",
    "doc_result = huggingface_embedding.embed_documents(chunks)\n",
    "doc_result[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "027d8ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_result[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
